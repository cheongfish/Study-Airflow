# Airflow Scheduler 
## 🎯 핵심 요약
- Airflow 스케줄러는 DAG과 태스크를 감시하고, 의존성이 충족되면 실행한다.
- 기본적으로 1분마다 DAG을 분석하고 실행할 태스크를 확인한다.
- `airflow scheduler` 명령어로 실행되며, 설정은 `airflow.cfg`를 따른다.
- DAG 실행은 **한 주기가 끝난 후** 실행되므로, UI에서는 실행이 지연된 것처럼 보일 수 있다.
- 스케줄러는 성능 최적화를 위해 실행 가능한 슬롯 개수만큼 태스크를 배치 실행한다.
- 태스크 우선순위는 실행 대기 중인 태스크가 슬롯 개수를 초과할 경우에만 영향을 미친다.
- DAG 파일을 지속적으로 파싱하고, 태스크를 실행하는 역할을 한다.
- 여러 개의 스케줄러를 실행할 수 있으며, PostgreSQL 12+ 또는 MySQL 8.0+을 권장한다.
- 성능 최적화를 위해 **파일 시스템, 데이터베이스, CPU, 메모리 사용량을 최적화**해야 한다.
- DAG 파일은 가볍게 유지해야 하며, 불필요한 연산은 최상위 레벨에서 피해야 한다.
---

## 1. 역할과 동작 방식
- Airflow 스케줄러는 DAG과 태스크를 모니터링하고, 태스크의 의존성이 충족되면 실행한다.
- 내부적으로 서브프로세스를 생성하여 DAG 디렉터리의 모든 DAG을 지속적으로 감시하고 동기화한다.
- 기본 설정에서는 1분에 한 번씩 DAG을 분석하고, 실행 가능한 태스크가 있는지 확인한다.

## 2. 실행 방법
- 스케줄러는 Airflow 프로덕션 환경에서 지속적으로 실행되는 서비스이다.
- `airflow scheduler` 명령어를 실행하면 스케줄러가 시작된다.
- 실행되면 `airflow.cfg` 파일의 설정을 기반으로 동작한다.
- 스케줄러는 설정된 Executor를 사용해 실행 준비가 완료된 태스크를 실행한다.

## 3. DAG 실행 시점
- 첫 번째 DAG 실행(DAG Run)은 DAG 내에서 가장 이른 `start_date` 기준으로 생성된다.
- 이후 DAG 실행은 DAG의 타임테이블(Timetable)에 따라 자동 생성된다.
- **Cron 또는 `timedelta` 스케줄을 사용하는 DAG**
  - 해당 주기가 끝난 후 태스크가 실행된다.
  - 예를 들어 `@daily` 스케줄의 DAG은 하루가 끝난 후 실행된다.
  - 따라서 UI에서는 Airflow가 하루 늦게 실행하는 것처럼 보일 수 있다.

## 4. 예제
- 만약 DAG이 하루 단위(`schedule_interval='1 day'`)로 실행된다면,
  - `2019-11-21`의 DAG 실행은 **`2019-11-21T23:59` 이후**에 트리거된다.
- 즉, 시작 날짜 이후 한 주기가 끝난 후 실행된다.

## 5. 스케줄러의 성능 최적화 방식
- Airflow 스케줄러는 높은 처리량(High Throughput) 설계를 기반으로 한다.
- 실행 가능한 슬롯(Pool 내 빈 슬롯)을 확인하고, 한 번에 최대 해당 개수만큼 태스크를 스케줄링한다.
- **우선순위(Task Priority)와 실행 순서**
  - 실행 가능한 슬롯이 많으면 태스크 우선순위는 영향을 미치지 않는다.
  - 같은 배치(Batch) 내에서는 낮은 우선순위 태스크가 높은 우선순위 태스크보다 먼저 실행될 수도 있다.
  - 더 자세한 논의는 **GitHub Discussion**을 참고하면 된다.

## DAG 파일 처리
- Airflow 스케줄러는 DAG 폴더에 있는 Python 파일을 DAG 객체로 변환하는 프로세스를 시작할 수 있다.
- 이에 대한 자세한 내용은 **DAG File Processing** 문서를 참고하면 된다.

## 미래 날짜의 DAG 실행 (Triggering DAG with Future Date)
- `external trigger`를 사용하여 미래 날짜의 데이터 간격을 실행하려면,  
  `airflow.cfg`의 `scheduler` 섹션에서 `allow_trigger_in_future = True`로 설정해야 한다.
- 단, 해당 설정은 **DAG의 `schedule`이 `None`일 때만 적용된다.**
- 기본값(False) 상태에서는 미래 날짜의 DAG을 수동으로 실행(trigger)하더라도,  
  `data_interval_start`가 과거 시점이 될 때까지 실행되지 않는다.

## 여러 개의 스케줄러 실행 (Running More Than One Scheduler)
- 성능 향상 및 장애 복구(Resiliency)를 위해 Airflow는 여러 개의 스케줄러를 동시에 실행할 수 있다.

### 개요
- HA(High Availability) 스케줄러는 기존의 메타데이터 데이터베이스를 활용한다.
- 기존 데이터베이스를 활용함으로써 **Zookeeper, Consul 같은 외부 컨센서스 도구를 사용하지 않고도** 운영이 간단해진다.
- 스케줄러는 **직렬화된 DAG(Serialized DAG) 정보를 사용하여** 스케줄링을 결정한다.

### 스케줄링 루프 개요
1. 실행이 필요한 DAG을 확인하고 **새로운 DagRun을 생성**한다.
2. 실행 가능한 **태스크(Task Instance)와 완료된 DAG Run을 검사**한다.
3. 실행 가능한 태스크를 선택하고, **Pool 및 동시 실행 제한을 고려하여** 실행 대기열(Executor)에 추가한다.

### 데이터베이스 요구사항
- **PostgreSQL 12+ 또는 MySQL 8.0+를 사용하면 별도의 설정 없이 다중 스케줄러를 실행 가능**하다.
- 다른 데이터베이스를 사용할 경우 추가적인 설정이 필요할 수 있다.

### 데이터베이스 동작 방식
- 스케줄링 루프에서 일부 계산은 **메모리 내에서 수행**되며,  
  데이터베이스에 직접 요청하면 성능 저하가 발생할 수 있다.
- 따라서, **SELECT ... FOR UPDATE와 같은 행 수준 잠금(Row-level Lock)** 을 사용하여,  
  한 번에 하나의 스케줄러만 중요한 작업을 수행하도록 보장한다.

### 지원되는 데이터베이스
✅ PostgreSQL 12+  
✅ MySQL 8.0+  

### ⚠️ 주의 사항
- **MariaDB**는 10.6.0 버전부터 `SKIP LOCKED`, `NOWAIT` SQL 구문을 지원하지만,  
  다중 스케줄러 환경에서 충분히 테스트되지 않았다.
- **Microsoft SQL Server**는 HA 모드에서 테스트되지 않았다.

## 스케줄러 성능 최적화 (Fine-tuning Scheduler Performance)

### 스케줄러 성능에 영향을 미치는 요소
스케줄러는 **DAG 파일을 파싱하고 태스크를 실행 스케줄링하는 역할**을 수행한다.  
이 두 가지 작업은 서로 독립적으로 실행된다.

다음 요소들이 성능에 영향을 미칠 수 있다:

1. **DAG 파일의 저장 방식**
   - DAG을 공유하는 파일 시스템 유형 (NFS, EFS, GCS, Azure Files 등)
   - 파일 시스템의 속도 (분산 파일 시스템에서는 성능 향상을 위해 추가 비용이 필요할 수도 있음)
   - DAG 파일의 크기 및 복잡성 (파일이 크거나 복잡할수록 파싱 속도가 느려짐)
   - DAG 파일이 외부 라이브러리를 많이 포함하고 있는지 여부 (최상위 레벨에서 무거운 연산을 수행하면 안 됨)

2. **하드웨어 자원**
   - **메모리(RAM)**: 충분한 메모리가 없으면 성능 저하 발생
   - **CPU**: DAG 파일을 지속적으로 파싱하기 때문에 CPU 사용량이 높음
   - **네트워크 대역폭**: DAG 파일이 원격 파일 시스템에서 읽히는 경우 네트워크 속도에 영향을 받을 수 있음

3. **스케줄러 구성**
   - 실행 중인 스케줄러 개수
   - DAG 파일을 파싱하는 프로세스 개수
   - 동일한 DAG을 재파싱하는 주기 (`min_file_process_interval`)
   - 한 번의 스케줄링 루프에서 처리하는 태스크 개수
   - 한 번의 루프에서 생성할 새로운 DAG Run 개수
   - **고아 태스크(Orphaned Tasks)를 감지하고 정리하는 빈도**

### 스케줄러 성능 조정 방법
1. **파일 시스템 최적화**
   - DAG 파일을 공유 파일 시스템 대신 **컨테이너 이미지에 포함하거나 GitSync 방식으로 배포**하면,  
     DAG이 로컬 디스크에서 읽히기 때문에 성능이 향상될 수 있다.

2. **데이터베이스 성능 최적화**
   - Airflow는 **데이터베이스 연결을 많이 사용**한다.
   - **PostgreSQL 환경에서는 PGBouncer를 사용하여 연결 풀링**을 적용하면 성능이 향상될 수 있다.

3. **CPU 사용량 최적화**
   - DAG 파일 파싱을 최적화하려면 **외부 API 호출, 복잡한 연산 등을 최상위 코드에서 수행하지 않도록** 해야 한다.

4. **메모리 사용량 최적화**
   - Airflow는 여러 개의 프로세스를 실행하며, 각 프로세스는 Python 인터프리터를 실행해야 하므로 메모리 사용량이 많다.

## 스케줄러 성능을 높이는 방법
1. **DAG 파일 최적화**
   - DAG 최상위 코드에서 **불필요한 연산, 외부 API 호출 등을 제거**해야 한다.

2. **자원 활용도 향상**
   - 현재 시스템의 CPU, 메모리, 네트워크 리소스가 충분히 활용되고 있는지 확인한다.

3. **하드웨어 업그레이드**
   - CPU나 I/O 성능이 부족하면 **스케줄러를 추가하거나, 더 좋은 하드웨어로 업그레이드**하는 것이 필요할 수 있다.

4. **튜닝 가능한 설정값 실험**
   - CPU 사용량을 줄이려면 **파일 재파싱 간격(`min_file_process_interval`)을 늘릴 수 있다.**  


