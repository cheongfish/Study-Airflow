# Airflow Scheduler 
## 🎯 핵심 요약
- Airflow 스케줄러는 DAG과 태스크를 감시하고, 의존성이 충족되면 실행한다.
- 기본적으로 1분마다 DAG을 분석하고 실행할 태스크를 확인한다.
- `airflow scheduler` 명령어로 실행되며, 설정은 `airflow.cfg`를 따른다.
- DAG 실행은 **한 주기가 끝난 후** 실행되므로, UI에서는 실행이 지연된 것처럼 보일 수 있다.
- 스케줄러는 성능 최적화를 위해 실행 가능한 슬롯 개수만큼 태스크를 배치 실행한다.
- 태스크 우선순위는 실행 대기 중인 태스크가 슬롯 개수를 초과할 경우에만 영향을 미친다.
- DAG 파일을 지속적으로 파싱하고, 태스크를 실행하는 역할을 한다.
- 여러 개의 스케줄러를 실행할 수 있으며, PostgreSQL 12+ 또는 MySQL 8.0+을 권장한다.
- 성능 최적화를 위해 **파일 시스템, 데이터베이스, CPU, 메모리 사용량을 최적화**해야 한다.
- DAG 파일은 가볍게 유지해야 하며, 불필요한 연산은 최상위 레벨에서 피해야 한다.
---

## 1. 역할과 동작 방식
- Airflow 스케줄러는 DAG과 태스크를 모니터링하고, 태스크의 의존성이 충족되면 실행한다.
- 내부적으로 서브프로세스를 생성하여 DAG 디렉터리의 모든 DAG을 지속적으로 감시하고 동기화한다.
- 기본 설정에서는 1분에 한 번씩 DAG을 분석하고, 실행 가능한 태스크가 있는지 확인한다.

## 2. 실행 방법
- 스케줄러는 Airflow 프로덕션 환경에서 지속적으로 실행되는 서비스이다.
- `airflow scheduler` 명령어를 실행하면 스케줄러가 시작된다.
- 실행되면 `airflow.cfg` 파일의 설정을 기반으로 동작한다.
- 스케줄러는 설정된 Executor를 사용해 실행 준비가 완료된 태스크를 실행한다.

## 3. DAG 실행 시점
- 첫 번째 DAG 실행(DAG Run)은 DAG 내에서 가장 이른 `start_date` 기준으로 생성된다.
- 이후 DAG 실행은 DAG의 타임테이블(Timetable)에 따라 자동 생성된다.
- **Cron 또는 `timedelta` 스케줄을 사용하는 DAG**
  - 해당 주기가 끝난 후 태스크가 실행된다.
  - 예를 들어 `@daily` 스케줄의 DAG은 하루가 끝난 후 실행된다.
  - 따라서 UI에서는 Airflow가 하루 늦게 실행하는 것처럼 보일 수 있다.

## 4. 예제
- 만약 DAG이 하루 단위(`schedule_interval='1 day'`)로 실행된다면,
  - `2019-11-21`의 DAG 실행은 **`2019-11-21T23:59` 이후**에 트리거된다.
- 즉, 시작 날짜 이후 한 주기가 끝난 후 실행된다.

## 5. 스케줄러의 성능 최적화 방식
- Airflow 스케줄러는 높은 처리량(High Throughput) 설계를 기반으로 한다.
- 실행 가능한 슬롯(Pool 내 빈 슬롯)을 확인하고, 한 번에 최대 해당 개수만큼 태스크를 스케줄링한다.
- **우선순위(Task Priority)와 실행 순서**
  - 실행 가능한 슬롯이 많으면 태스크 우선순위는 영향을 미치지 않는다.
  - 같은 배치(Batch) 내에서는 낮은 우선순위 태스크가 높은 우선순위 태스크보다 먼저 실행될 수도 있다.
  - 더 자세한 논의는 **GitHub Discussion**을 참고하면 된다.




