## DAG 파일 처리
- Airflow 스케줄러는 DAG 폴더에 있는 Python 파일을 DAG 객체로 변환하는 프로세스를 시작할 수 있다.
- 이에 대한 자세한 내용은 **DAG File Processing** 문서를 참고하면 된다.

## 미래 날짜의 DAG 실행 (Triggering DAG with Future Date)
- `external trigger`를 사용하여 미래 날짜의 데이터 간격을 실행하려면,  
  `airflow.cfg`의 `scheduler` 섹션에서 `allow_trigger_in_future = True`로 설정해야 한다.
- 단, 해당 설정은 **DAG의 `schedule`이 `None`일 때만 적용된다.**
- 기본값(False) 상태에서는 미래 날짜의 DAG을 수동으로 실행(trigger)하더라도,  
  `data_interval_start`가 과거 시점이 될 때까지 실행되지 않는다.

## 여러 개의 스케줄러 실행 (Running More Than One Scheduler)
- 성능 향상 및 장애 복구(Resiliency)를 위해 Airflow는 여러 개의 스케줄러를 동시에 실행할 수 있다.

### 개요
- HA(High Availability) 스케줄러는 기존의 메타데이터 데이터베이스를 활용한다.
- 기존 데이터베이스를 활용함으로써 **Zookeeper, Consul 같은 외부 컨센서스 도구를 사용하지 않고도** 운영이 간단해진다.
- 스케줄러는 **직렬화된 DAG(Serialized DAG) 정보를 사용하여** 스케줄링을 결정한다.

### 스케줄링 루프 개요
1. 실행이 필요한 DAG을 확인하고 **새로운 DagRun을 생성**한다.
2. 실행 가능한 **태스크(Task Instance)와 완료된 DAG Run을 검사**한다.
3. 실행 가능한 태스크를 선택하고, **Pool 및 동시 실행 제한을 고려하여** 실행 대기열(Executor)에 추가한다.

### 데이터베이스 요구사항
- **PostgreSQL 12+ 또는 MySQL 8.0+를 사용하면 별도의 설정 없이 다중 스케줄러를 실행 가능**하다.
- 다른 데이터베이스를 사용할 경우 추가적인 설정이 필요할 수 있다.

### 데이터베이스 동작 방식
- 스케줄링 루프에서 일부 계산은 **메모리 내에서 수행**되며,  
  데이터베이스에 직접 요청하면 성능 저하가 발생할 수 있다.
- 따라서, **SELECT ... FOR UPDATE와 같은 행 수준 잠금(Row-level Lock)** 을 사용하여,  
  한 번에 하나의 스케줄러만 중요한 작업을 수행하도록 보장한다.

### 지원되는 데이터베이스
✅ PostgreSQL 12+  
✅ MySQL 8.0+  

### ⚠️ 주의 사항
- **MariaDB**는 10.6.0 버전부터 `SKIP LOCKED`, `NOWAIT` SQL 구문을 지원하지만,  
  다중 스케줄러 환경에서 충분히 테스트되지 않았다.
- **Microsoft SQL Server**는 HA 모드에서 테스트되지 않았다.

## 스케줄러 성능 최적화 (Fine-tuning Scheduler Performance)

### 스케줄러 성능에 영향을 미치는 요소
스케줄러는 **DAG 파일을 파싱하고 태스크를 실행 스케줄링하는 역할**을 수행한다.  
이 두 가지 작업은 서로 독립적으로 실행된다.

다음 요소들이 성능에 영향을 미칠 수 있다:

1. **DAG 파일의 저장 방식**
   - DAG을 공유하는 파일 시스템 유형 (NFS, EFS, GCS, Azure Files 등)
   - 파일 시스템의 속도 (분산 파일 시스템에서는 성능 향상을 위해 추가 비용이 필요할 수도 있음)
   - DAG 파일의 크기 및 복잡성 (파일이 크거나 복잡할수록 파싱 속도가 느려짐)
   - DAG 파일이 외부 라이브러리를 많이 포함하고 있는지 여부 (최상위 레벨에서 무거운 연산을 수행하면 안 됨)

2. **하드웨어 자원**
   - **메모리(RAM)**: 충분한 메모리가 없으면 성능 저하 발생
   - **CPU**: DAG 파일을 지속적으로 파싱하기 때문에 CPU 사용량이 높음
   - **네트워크 대역폭**: DAG 파일이 원격 파일 시스템에서 읽히는 경우 네트워크 속도에 영향을 받을 수 있음

3. **스케줄러 구성**
   - 실행 중인 스케줄러 개수
   - DAG 파일을 파싱하는 프로세스 개수
   - 동일한 DAG을 재파싱하는 주기 (`min_file_process_interval`)
   - 한 번의 스케줄링 루프에서 처리하는 태스크 개수
   - 한 번의 루프에서 생성할 새로운 DAG Run 개수
   - **고아 태스크(Orphaned Tasks)를 감지하고 정리하는 빈도**

### 스케줄러 성능 조정 방법
1. **파일 시스템 최적화**
   - DAG 파일을 공유 파일 시스템 대신 **컨테이너 이미지에 포함하거나 GitSync 방식으로 배포**하면,  
     DAG이 로컬 디스크에서 읽히기 때문에 성능이 향상될 수 있다.

2. **데이터베이스 성능 최적화**
   - Airflow는 **데이터베이스 연결을 많이 사용**한다.
   - **PostgreSQL 환경에서는 PGBouncer를 사용하여 연결 풀링**을 적용하면 성능이 향상될 수 있다.

3. **CPU 사용량 최적화**
   - DAG 파일 파싱을 최적화하려면 **외부 API 호출, 복잡한 연산 등을 최상위 코드에서 수행하지 않도록** 해야 한다.

4. **메모리 사용량 최적화**
   - Airflow는 여러 개의 프로세스를 실행하며, 각 프로세스는 Python 인터프리터를 실행해야 하므로 메모리 사용량이 많다.

## 스케줄러 성능을 높이는 방법
1. **DAG 파일 최적화**
   - DAG 최상위 코드에서 **불필요한 연산, 외부 API 호출 등을 제거**해야 한다.

2. **자원 활용도 향상**
   - 현재 시스템의 CPU, 메모리, 네트워크 리소스가 충분히 활용되고 있는지 확인한다.

3. **하드웨어 업그레이드**
   - CPU나 I/O 성능이 부족하면 **스케줄러를 추가하거나, 더 좋은 하드웨어로 업그레이드**하는 것이 필요할 수 있다.

4. **튜닝 가능한 설정값 실험**
   - CPU 사용량을 줄이려면 **파일 재파싱 간격(`min_file_process_interval`)을 늘릴 수 있다.**  